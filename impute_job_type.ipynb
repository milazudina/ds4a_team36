{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "impute_job_type.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM8gcdWunB1txBnO8LCH9Gr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/milazudina/ds4a_team36/blob/main/impute_job_type.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1MHIYkeHKoY",
        "outputId": "d383441a-81cf-41a2-8df7-4c5f3a1ebd43"
      },
      "source": [
        "import pandas as pd\n",
        "import spacy\n",
        "import random\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, Embedding, SpatialDropout1D, Flatten\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.convolutional import MaxPooling1D\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import one_hot\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "nltk.download('stopwords')\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "STOPWORDS = set(stopwords.words('english'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zA-qrf3pXShm"
      },
      "source": [
        "Code below does the following:\n",
        "\n",
        "1.   Load the Kaggle job description (JDs) dataset\n",
        "  *  Remove all the job postings that don't have either a JD or a Job Type\n",
        "  *  Extract a unique set of noun phrases for each Job Posting\n",
        "\n",
        "2.   Build a deep learning model and assess its accuracy\n",
        "\n",
        "3.   Predict the Job Types for the scraped job descriptions\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxiGd-IcFh73"
      },
      "source": [
        "kaggle_df = pd.read_csv(\"indeed_job_dataset.csv\")\n",
        "\n",
        "#print(kaggle_df['Description'][6])\n",
        "#print(kaggle_df['Job_Type'][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtslGVBuHVVA"
      },
      "source": [
        "# 302 jobs do not have a description that we will use to infer the job type, hence let's remove these from the dataframe\n",
        "kaggle_df = kaggle_df[kaggle_df.Description.notnull()]\n",
        "kaggle_df.reset_index(drop=True, inplace=True)\n",
        "kaggle_df.shape\n",
        "print(kaggle_df.isnull().sum(axis = 0))\n",
        "kaggle_df.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "kLpSiS2yNkc0",
        "outputId": "0990cace-e44d-40fc-db95-aec5fbcaaadf"
      },
      "source": [
        "# tidy up the job description text\n",
        "\n",
        "kaggle_df[\"Description_tidy\"] = 0\n",
        "i = 0\n",
        "\n",
        "for job_description in kaggle_df['Description']:\n",
        "\n",
        "    ## Clean the text\n",
        "  job_description = job_description.lower().replace(\"\\n\", \"\").replace(\"</b>\", \"\").replace(\"</p>\", \"\").replace(\"<b>\", \"\").replace(\"<p>\", \"\").replace(\"</li>\", \"\").replace(\"</ul>\", \"\").replace(\"<li>\", \"\").replace(\"<ul>\", \"\").replace(\"<i>\", \"\").replace(\"</i>\", \"\").replace(\"\\r\", \"\").replace(\"<div>\", \"\").replace(\"h2\", \"\").replace(\"h3\",\"\").replace(\"h1\",\"\")\n",
        "  job_description = job_description.replace(\"</h1>\", \"\").replace(\"</div>\", \"\").replace(\"/h2\", \"\").replace(\"/h3\",\"\")\n",
        "  job_description = re.sub(\"-\", \" \", job_description)\n",
        "  job_description = re.sub(\"/\", \" \", job_description)\n",
        "  job_description = re.sub(\" a \", \" \", job_description)\n",
        "  job_description = re.sub(\" an \", \" \", job_description)\n",
        "  job_description = re.sub(\"[0-9]\", \"\", job_description)\n",
        "  job_description = job_description.replace(\" the \", \" \").replace(\")\", \"\").replace(\"(\", \"\").replace(\"e.g.\", \"\").replace(\"£\", \"\").replace(\"$\", \"\").replace(\"%\", \"\").replace(\"e g\", \"\").replace(\".\", \" \").replace(\",\", \" \").replace(\":\", \"\").replace(\";\", \"\").replace(\"?\", \"\").replace(\"*\", \"\").replace(\" eg \", \"\").replace(\">\", \"\").replace(\"<\", \"\")\n",
        "  temp = [w for w in job_description.split(\" \") if not w in STOPWORDS]\n",
        "  job_description = \" \".join(temp)\n",
        "\n",
        "  text = nlp(job_description)  \n",
        "  noun_phrases = [chunk.text for chunk in text.noun_chunks] \n",
        "  noun_phrases = np.array(noun_phrases)\n",
        "  noun_phrases = np.unique(noun_phrases)\n",
        "  job_description = \" \".join(noun_phrases)\n",
        "\n",
        "  kaggle_df[\"Description_tidy\"][i] = job_description\n",
        "\n",
        "  i = i + 1\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-d6b08f9614aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# tidy up the job description text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mkaggle_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Description_tidy\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'kaggle_df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qjOkU6pmVzQf",
        "outputId": "dc3935e2-5648-4176-8a02-071bc99d6bb0"
      },
      "source": [
        "print(kaggle_df['Description'][0])\n",
        "print(\"\\n\")\n",
        "print(kaggle_df['Description_tidy'][0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[<p><b>POSITION SUMMARY</b></p>, <p>\r\r\n",
            "The Business Analyst role is the primary architect of reporting and dashboard solutions for internal and external clients. Utilizing ESI corporate standard development tools this position is responsible for the design, development, implementation, analysis, interpretation and communication of business information based on the needs of individual clients. The ability to balance overall aesthetics with robust and intuitive functionality is a critical requirement for success in this position.</p>, <p><b>\r\r\n",
            "ESSENTIAL FUNCTIONS</b></p>, <ul><li>\r\r\n",
            "Successfully design and implement external client data reporting and dashboard solutions with a strong focus on product aesthetics and functionality.</li><li>\r\r\n",
            "Aid in the design, development, and implementation of new product ideas for external and internal clients.</li><li>\r\r\n",
            "Maintain Live and Data Warehouse Business Objects Universes; add new fields, modify table joins, implement data structures that streamline report extraction and data analysis.</li><li>\r\r\n",
            "Develop and document best practices for all points throughout the design and implementation process.</li><li>\r\r\n",
            "Coordinate and interface with Account Management and Implementation teams to gather product design requirements and provide insight into capabilities and solutions.</li><li>\r\r\n",
            "Research and present new software and technology solutions to other internal developers, as well as management, to allow for the evaluation and potential integration of new development tools.</li></ul>, <p><b>QUALIFICATIONS</b></p>, <ul><li><p>\r\r\n",
            "Bachelor’s degree in related field or 8 to 11 years of experience.</p></li><li>\r\r\n",
            "2-5 years relevant experience with Bachelor’s Degree or Master’s degree and 0-3 years of relevant experience.</li><li>\r\r\n",
            "Recent experience creating Business Objects XI reports.</li><li>\r\r\n",
            "Designing data visualization applications using SAP Xcelsius 2008 software.</li><li>\r\r\n",
            "Designing, implementing and maintaining data universe structures using Business Objects Universe Designer.</li><li>\r\r\n",
            "SQL, AS400, Adobe Flex, Flash experience preferred.</li><li>\r\r\n",
            "Creative problem solver.</li><li>\r\r\n",
            "Fundamental commitment to creating customer value through technical innovation.<br/>\r\r\n",
            "</li></ul>, <p>\r\r\n",
            "Bachelor’s degree in related field or 8 to 11 years of experience.</p>, <p><b>\r\r\n",
            "ABOUT THE DEPARTMENT</b></p>, <p><b>\r\r\n",
            "ABOUT EXPRESS SCRIPTS</b></p>, <p>\r\r\n",
            "Advance your career with the company that makes it easier for people to choose better health.</p>, <p>\r\r\n",
            "Express Scripts is a leading healthcare company serving tens of millions of consumers. We are looking for individuals who are passionate, creative and committed to creating systems and service solutions that promote better health outcomes. Join the company that Fortune magazine ranked as one of the \"Most Admired Companies\" in the pharmacy category. Then, use your intelligence, creativity, integrity and hard work to help us enhance our products and services. We offer a highly competitive base salary and a comprehensive benefits program, including medical, prescription drug, dental, vision, 401(k) with company match, life insurance, paid time off, tuition assistance and an employee stock purchase plan.</p>, <p>\r\r\n",
            "Express Scripts is an equal opportunity employer/disability/veteran</p>]\n",
            "\n",
            "\n",
            "ability advance career company bachelor’s degree related field   years experience better health   express scripts leading healthcare company better health outcomes br   bachelor’s degree related field   years experience business objects creative committed creating systems service solutions creativity  integrity customer value technical innovation data structures data universe structures data visualization applications degree master department  express scripts design implementation process development development  implementation new product ideas external internal clients document best practices points easier people esi corporate standard development tools essential functions evaluation potential integration new development tools express scripts equal opportunity employer disability veteran focus product aesthetics functionality aid design hard work highly competitive base salary comprehensive benefits program implement implementation  analysis  interpretation communication business information individual clients insight capabilities solutions research present new software technology solutions internal developers interface account management implementation teams join company fortune magazine k company life insurance looking individuals management medical  prescription drug modify table new fields one \"most admired companies pharmacy category position responsible design position summary  business analyst role primary architect reporting dashboard solutions internal external clients preferred creative problem solver fundamental commitment product design requirements products services recent experience report extraction data analysis tens millions consumers time tuition assistance employee stock purchase plan universe designer sql   adobe flex  flash experience universes us use intelligence vision xi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p0lI0yC_V9Cn",
        "outputId": "f612a6fa-a04b-400b-cb32-375b5f64de8d"
      },
      "source": [
        "kaggle_df = kaggle_df[kaggle_df.Description_tidy != 0]\n",
        "kaggle_JDs = np.asarray(kaggle_df[\"Description_tidy\"])\n",
        "\n",
        "y = kaggle_df['Job_Type'] # labels\n",
        "print(y.value_counts())\n",
        "y = y.tolist()\n",
        "\n",
        "# prepare tokenizer\n",
        "t = Tokenizer()\n",
        "t.fit_on_texts(kaggle_JDs)\n",
        "vocab_size = len(t.word_index)+1\n",
        "print(vocab_size)\n",
        "\n",
        "# integer encode the documents\n",
        "encoded_JDs = t.texts_to_sequences(kaggle_JDs)\n",
        "print(len(encoded_JDs))\n",
        "\n",
        "list_len = [len(i) for i in encoded_JDs]\n",
        "\n",
        "# pad documents to a max length\n",
        "max_length = max(list_len)\n",
        "print(max(list_len))\n",
        "padded_JDs = pad_sequences(encoded_JDs, maxlen=max_length, padding = 'post')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data_scientist    2376\n",
            "data_analyst      1535\n",
            "data_engineer     1309\n",
            "Name: Job_Type, dtype: int64\n",
            "36292\n",
            "5220\n",
            "915\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BG6BCKNSXK-2",
        "outputId": "1f08e190-faed-480c-a40c-b88de94cd445"
      },
      "source": [
        "print(kaggle_JDs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['ability advance career company bachelor’s degree related field   years experience better health   express scripts leading healthcare company better health outcomes br   bachelor’s degree related field   years experience business objects creative committed creating systems service solutions creativity  integrity customer value technical innovation data structures data universe structures data visualization applications degree master department  express scripts design implementation process development development  implementation new product ideas external internal clients document best practices points easier people esi corporate standard development tools essential functions evaluation potential integration new development tools express scripts equal opportunity employer disability veteran focus product aesthetics functionality aid design hard work highly competitive base salary comprehensive benefits program implement implementation  analysis  interpretation communication business information individual clients insight capabilities solutions research present new software technology solutions internal developers interface account management implementation teams join company fortune magazine k company life insurance looking individuals management medical  prescription drug modify table new fields one \"most admired companies pharmacy category position responsible design position summary  business analyst role primary architect reporting dashboard solutions internal external clients preferred creative problem solver fundamental commitment product design requirements products services recent experience report extraction data analysis tens millions consumers time tuition assistance employee stock purchase plan universe designer sql   adobe flex  flash experience universes us use intelligence vision xi'\n",
            " 'advanced degree masters amazing personality communication style applied mathematics  operations research benefits br experience br job descriptionbr position br skills br sound credit policies critical thinking development programs economics  quantitative finance education eeo guidelines employees employmentcompany entry level position everything exciting career organization fosters experience statistical modeling fields extensive training future success holidayspto importantly unquestionable integrity information interested career specialized quantitative risk management discipline internal external reviewscommunicate technical information k   tuition reimbursement marketing  credit risk models mbas modeling projectsunderstand modelsdeliver comprehensive model documentation   model development document preferred statistics pride problem python working experience sqldetail range languages sas risk analyticsperform segmentation skillsexcellent verbal written communication skills solver statistics strong knowledge statistics methods machine technical non technical audiences technical regulatory documentation techniquesstrong numerical programming ability tests measures today!br us vision benefits what you'\n",
            " 'ability manage accuracy alternative solutions research management business decision makers analysis opportunities analytical fieldexperience assignments bachelor degree statistics changing deadlines client business clients competing requirements daily industry news data data requirements deadlines decision sciences define effectivraphs efficient  responsible  dependable experience television media research industry execute test cases formulae  vlookups functional requirements research projects graphingstrong organizational skills initiative intrinsic ability issues large amounts information key findings ability li jz  msja mathematics minimal direction multiple tasks conditions narratives new knowledge strong documentation skills business technology perspective effective troubleshooting investigation skills one data analysis packages patterns pivot tables present findings problems python programming qualitative findings large data sets relevant articles management team reports research resolve client research written verbal presentations software developers results root sales staff data management sas self starter self similar field skills spss sql statistical analysis data strong attention detail problem summaries tables workloads years experience'\n",
            " ...\n",
            " 'advantage cloud provider api gateways apigeeexperience microservice event applications expertise design data architecture private data architecturesfamiliarity lambda aws  services technologies big data core data services expertise cloud ci cd closaps  collaborate driving maturity discipline closapsestablish drive cohesive metadata strategy cloud consumption containers data persistence control scale coverage  propagation data access data engineering experience data governance data management data management fabricidentify elevate capability featuraps data management fabricidentify elevate capability featuraps sre telemetry backlog clear sprints data migration data lifecycle data provisioning consumption velocityexcellent organizational  communication  influence execution skills data replication strategies data services domain driven design concepts engineering enrichment ensure firm industry glue hadoop cassandra hybrid cloud data engineering sustainable data governance workloads data hybrid cloud environment control scale hybrid cloud environments engineering ibm identify opportunities ingestion integrated end end view inventory resource tag annotation strategies java kafka kappa architectures data intensive applicationsshows passion hands key areas includeexperience managementthe data catalog model registry metadata metadata enable compliant quality registration metadata metadata modern data engineeringprepare challenges moved lineage increasing capture use mq legacysolid understanding software delivery nosql database technologies open source technology advancements platforms provisioning information delivery reconciliation hybrid cloudcollaborate driving maturity discipline redshifexperience spark related microservices resiliency designs rigor data management practices spring service implementations sre telemetry backlog clear sprints teams terraform tooling automation transparency data'\n",
            " 'advocacy exhibit analysts ansible   terraformexperience associates automated testing tdd practicesat bachelor’s degree military experienceat bar technical excellencedevelop code meet story acceptance br br breakers capital capital one  looking software engineers strong fundamentals chairman chief executive officer cicd pipeline circleci code code meet acceptance criterianavigate organization necessary unblock team compliance standards curiosity curious ask customers data driven services power machine learning capabilities digital products data scientists difference  million customers doers dreams elevate obsess right thing engineers enhancements equivalentexperience publish subscribe queuing systems exampleinfluence peer teams leadership founder functional programming language goals good   senior manager  data engineering hands humility ingenuity innovation insights java performance jenkins jvm key decision key player team functions large corporation role latest technologies leading information based technology company least  years least  years application development experienceat least  years experience least  years experience version control systemsat least  years experience writing software less experienced people managers love measure mode monitoringexperience working spring frameworksexperience new applicationsconduct design code review new qualified applicant employment authorization position one engineers one mission oral communicationopen source contribution part big group makers people management responsibilities perl perspective teamwork respect product delivery strategy qualityestimate level effort quest change real problems reasonable roadmaps  timelinescollaborate recruit  manage responsibility retain team talented engineersmentor richard fairbank rubyexperience building systems scalaexperience scripting languages python services shared values simplicity simplicity humanity banking software  builds products experiment software development life cyclecollaborate product engineering leadership sqs streaming architectureexperience working dockerexperience success customers superior results team technical ownership projectsat technology culture thrive environment collaboration openness timely delivery tinker new technology we what work tech company working public private cloud infrastructure  exposure'\n",
            " 'ajax analysis collaborates subject matter experts analytics software analyzes system capabilities autonomous services benchmarks designs big data analytics big data technologies citizenship required  bachelors computer science closely related discipline clearance computer user customized  commercial software data repositories data visualization debugs application software design  development desktop applications distribution data documents end product experience experience development use government data analysis four  years experienceexperience full open source hadoop stack cluster management identifies performance bottle necks input data acquisition interactive visualizationssource code control systemsrelational java javascript  html jqueryweb frameworks json manipulation masters minimal travel required position nine  years experience nodes nosql databases open source container resource management open source visualization technologies operating instructions designs output requirements parallel data intensive systems performance nosql repositories phd premises public cloud environments presentation problems program intent programming techniques progressively responsible experience software development scalable systems schedulers sci polyu software engineering  data software standards success technologies languages utility programs utilization electronic data processing systems information storage web applications web proxy servers working agile development environments']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7TcWz691Yo47",
        "outputId": "69591634-dec6-47d9-f420-acd366b443f7"
      },
      "source": [
        "def make_dummy_var(y):\n",
        "  temp = np.zeros([len(y), 3])\n",
        "  for i in range(0,len(y)):\n",
        "    if y[i] == 'data_scientist':\n",
        "      temp[i,0] = 1\n",
        "      temp[i,1] = 0\n",
        "      temp[i,2] = 0\n",
        "    elif y[i] == 'data_analyst':\n",
        "      temp[i,0] = 0\n",
        "      temp[i,1] = 1\n",
        "      temp[i,2] = 0\n",
        "    elif y[i] == 'data_engineer':\n",
        "      temp[i,0] = 0\n",
        "      temp[i,1] = 0\n",
        "      temp[i,2] = 1\n",
        "  return temp\n",
        "\n",
        "y_onehot = make_dummy_var(y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(padded_JDs, y_onehot, test_size=0.33)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)\n",
        "\n",
        "print(len(y_train[y_train[:,0] == 1])/(len(y_train[y_train[:,0] == 0])+len(y_train[y_train[:,0] == 1])))\n",
        "print(len(y_test[y_test[:,0] == 1])/(len(y_test[y_test[:,0] == 0])+len(y_test[y_test[:,0] == 1])))\n",
        "\n",
        "print(len(y_train[y_train[:,1] == 1])/(len(y_train[y_train[:,1] == 0])+len(y_train[y_train[:,1] == 1])))\n",
        "print(len(y_test[y_test[:,1] == 1])/(len(y_test[y_test[:,1] == 0])+len(y_test[y_test[:,1] == 1])))\n",
        "\n",
        "print(len(y_train[y_train[:,2] == 1])/(len(y_train[y_train[:,2] == 0])+len(y_train[y_train[:,2] == 1])))\n",
        "print(len(y_test[y_test[:,2] == 1])/(len(y_test[y_test[:,2] == 0])+len(y_test[y_test[:,2] == 1])))\n",
        "\n",
        "print(y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3497, 915)\n",
            "(1723, 915)\n",
            "(3497, 3)\n",
            "(1723, 3)\n",
            "0.4566771518444381\n",
            "0.4521183981427742\n",
            "0.2942522161853017\n",
            "0.293673824724318\n",
            "0.24907063197026022\n",
            "0.2542077771329077\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6rG8lE_r9rI"
      },
      "source": [
        "# Run this only if using pretrained embedding matrix\n",
        "\n",
        "embeddings_index = dict()\n",
        "# can download from https://nlp.stanford.edu/projects/glove/\n",
        "f = open('glove.6B.100d.txt')\n",
        "for line in f:\n",
        "\tvalues = line.split()\n",
        "\tword = values[0]\n",
        "\tcoefs = np.asarray(values[1:], dtype='float32')\n",
        "\tembeddings_index[word] = coefs\n",
        "f.close()\n",
        "print('Loaded %s word vectors.' % len(embeddings_index))\n",
        "\n",
        "# create a weight matrix for words in training docs\n",
        "embedding_matrix = np.zeros((vocab_size, 100))\n",
        "count = 0\n",
        "for word, i in t.word_index.items():\n",
        "\t#print(word)\n",
        "\tembedding_vector = embeddings_index.get(word)\n",
        "\tif embedding_vector is not None:\n",
        "\t\tcount = count + 1\n",
        "\t\tembedding_matrix[i] = embedding_vector\n",
        "\n",
        "print(count)\n",
        "\n",
        "glove_layer = Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=max_length, trainable=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fW7JQYATsk-h"
      },
      "source": [
        "model = Sequential()\n",
        "# model.add(glove_layer) # uncomment this only if using pretrained embedding matrix\n",
        "model.add(Embedding(vocab_size, 100, input_length=max_length))\n",
        "model.add(Conv1D(filters=144, kernel_size=8, activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(72, activation='relu'))\n",
        "model.add(Dense(24, activation='relu'))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "\n",
        "Adam = keras.optimizers.Adam(learning_rate=0.001)\n",
        "\n",
        "model.compile(optimizer=Adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "print(model.summary())\n",
        "\n",
        "# add learning rate parameter\n",
        "\n",
        "# fit the model\n",
        "model.fit(X_train, y_train, epochs=20, verbose=1, batch_size=32)\n",
        "\n",
        "# evaluate the model\n",
        "loss, accuracy = model.evaluate(X_train, y_train, verbose=0)\n",
        "print('Accuracy: %f' % (accuracy*100))\n",
        "\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "print('Test accuracy: %f' % (test_accuracy*100))\n",
        "\n",
        "# With pre-trained embedding:\n",
        "# Accuracy: 99.779373\n",
        "# 56/56 [==============================] - 3s 51ms/step - loss: 1.1872 - accuracy: 0.8075\n",
        "# Test accuracy: 80.749857\n",
        "\n",
        "# With embedding trained on thie kaggle set.\n",
        "# Accuracy: 99.685442\n",
        "# 54/54 [==============================] - 7s 129ms/step - loss: 0.7627 - accuracy: 0.8601\n",
        "# Test accuracy: 86.012769"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GuBMa2yiA2bF"
      },
      "source": [
        "The section below repeats some steps in the section above but for a combination of kaggle + indeed datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8YgoclgX-RpH",
        "outputId": "8ba3dd2d-d400-40f3-80e9-98387a0796db"
      },
      "source": [
        "indeed_df = pd.read_csv(\"df_UK_2021-10-04_with_skills.csv\")\n",
        "indeed_df.head(10)\n",
        "\n",
        "# tidy up the job description text\n",
        "\n",
        "indeed_df[\"Description_tidy\"] = 0\n",
        "i = 0\n",
        "\n",
        "for job_description in indeed_df['Description']:\n",
        "\n",
        "    ## Clean the text\n",
        "  job_description = job_description.lower().replace(\"\\n\", \"\").replace(\"</b>\", \"\").replace(\"</p>\", \"\").replace(\"<b>\", \"\").replace(\"<p>\", \"\").replace(\"</li>\", \"\").replace(\"</ul>\", \"\").replace(\"<li>\", \"\").replace(\"<ul>\", \"\").replace(\"<i>\", \"\").replace(\"</i>\", \"\").replace(\"\\r\", \"\").replace(\"<div>\", \"\").replace(\"h2\", \"\").replace(\"h3\",\"\").replace(\"h1\",\"\")\n",
        "  job_description = job_description.replace(\"</h1>\", \"\").replace(\"</div>\", \"\").replace(\"/h2\", \"\").replace(\"/h3\",\"\")\n",
        "  job_description = re.sub(\"-\", \" \", job_description)\n",
        "  job_description = re.sub(\"/\", \" \", job_description)\n",
        "  job_description = re.sub(\" a \", \" \", job_description)\n",
        "  job_description = re.sub(\" an \", \" \", job_description)\n",
        "  job_description = re.sub(\"[0-9]\", \"\", job_description)\n",
        "  job_description = job_description.replace(\" the \", \" \").replace(\")\", \"\").replace(\"(\", \"\").replace(\"e.g.\", \"\").replace(\"£\", \"\").replace(\"$\", \"\").replace(\"%\", \"\").replace(\"e g\", \"\").replace(\".\", \" \").replace(\",\", \" \").replace(\":\", \"\").replace(\";\", \"\").replace(\"?\", \"\").replace(\"*\", \"\").replace(\" eg \", \"\").replace(\">\", \"\").replace(\"<\", \"\")\n",
        "  temp = [w for w in job_description.split(\" \") if not w in STOPWORDS]\n",
        "  job_description = \" \".join(temp)\n",
        "\n",
        "  text = nlp(job_description)  \n",
        "  noun_phrases = [chunk.text for chunk in text.noun_chunks] \n",
        "  noun_phrases = np.array(noun_phrases)\n",
        "  noun_phrases = np.unique(noun_phrases)\n",
        "  job_description = \" \".join(noun_phrases)\n",
        "\n",
        "  indeed_df[\"Description_tidy\"][i] = job_description\n",
        "\n",
        "  i = i + 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py:670: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  iloc._setitem_with_indexer(indexer, value)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PVUdAe5X-4V9",
        "outputId": "e7850a90-d3ca-47a0-ebe4-cabdc0c23b81"
      },
      "source": [
        "indeed_JDs = np.asarray(indeed_df[\"Description_tidy\"])\n",
        "kaggle_df = kaggle_df[kaggle_df.Description_tidy != 0]\n",
        "kaggle_JDs = np.asarray(kaggle_df[\"Description_tidy\"])\n",
        "combined_JDs = np.concatenate((kaggle_JDs, indeed_JDs), axis=None)\n",
        "\n",
        "y = kaggle_df['Job_Type'] # labels\n",
        "print(y.value_counts())\n",
        "y = y.tolist()\n",
        "\n",
        "# prepare tokenizer\n",
        "t = Tokenizer()\n",
        "t.fit_on_texts(combined_JDs)\n",
        "vocab_size = len(t.word_index)+1\n",
        "print(vocab_size)\n",
        "\n",
        "# integer encode the documents\n",
        "encoded_JDs = t.texts_to_sequences(combined_JDs)\n",
        "print(len(encoded_JDs))\n",
        "\n",
        "list_len = [len(i) for i in encoded_JDs]\n",
        "\n",
        "# pad documents to a max length\n",
        "max_length = max(list_len)\n",
        "print(max(list_len))\n",
        "padded_JDs = pad_sequences(encoded_JDs, maxlen=max_length, padding = 'post')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data_scientist    2376\n",
            "data_analyst      1535\n",
            "data_engineer     1309\n",
            "Name: Job_Type, dtype: int64\n",
            "41004\n",
            "6363\n",
            "926\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQr9uTcaAGWa",
        "outputId": "fca22716-a0b6-4b07-ccd2-9f7f8d1eff31"
      },
      "source": [
        "print(combined_JDs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['ability advance career company bachelor’s degree related field   years experience better health   express scripts leading healthcare company better health outcomes br   bachelor’s degree related field   years experience business objects creative committed creating systems service solutions creativity  integrity customer value technical innovation data structures data universe structures data visualization applications degree master department  express scripts design implementation process development development  implementation new product ideas external internal clients document best practices points easier people esi corporate standard development tools essential functions evaluation potential integration new development tools express scripts equal opportunity employer disability veteran focus product aesthetics functionality aid design hard work highly competitive base salary comprehensive benefits program implement implementation  analysis  interpretation communication business information individual clients insight capabilities solutions research present new software technology solutions internal developers interface account management implementation teams join company fortune magazine k company life insurance looking individuals management medical  prescription drug modify table new fields one \"most admired companies pharmacy category position responsible design position summary  business analyst role primary architect reporting dashboard solutions internal external clients preferred creative problem solver fundamental commitment product design requirements products services recent experience report extraction data analysis tens millions consumers time tuition assistance employee stock purchase plan universe designer sql   adobe flex  flash experience universes us use intelligence vision xi'\n",
            " 'advanced degree masters amazing personality communication style applied mathematics  operations research benefits br experience br job descriptionbr position br skills br sound credit policies critical thinking development programs economics  quantitative finance education eeo guidelines employees employmentcompany entry level position everything exciting career organization fosters experience statistical modeling fields extensive training future success holidayspto importantly unquestionable integrity information interested career specialized quantitative risk management discipline internal external reviewscommunicate technical information k   tuition reimbursement marketing  credit risk models mbas modeling projectsunderstand modelsdeliver comprehensive model documentation   model development document preferred statistics pride problem python working experience sqldetail range languages sas risk analyticsperform segmentation skillsexcellent verbal written communication skills solver statistics strong knowledge statistics methods machine technical non technical audiences technical regulatory documentation techniquesstrong numerical programming ability tests measures today!br us vision benefits what you'\n",
            " 'ability manage accuracy alternative solutions research management business decision makers analysis opportunities analytical fieldexperience assignments bachelor degree statistics changing deadlines client business clients competing requirements daily industry news data data requirements deadlines decision sciences define effectivraphs efficient  responsible  dependable experience television media research industry execute test cases formulae  vlookups functional requirements research projects graphingstrong organizational skills initiative intrinsic ability issues large amounts information key findings ability li jz  msja mathematics minimal direction multiple tasks conditions narratives new knowledge strong documentation skills business technology perspective effective troubleshooting investigation skills one data analysis packages patterns pivot tables present findings problems python programming qualitative findings large data sets relevant articles management team reports research resolve client research written verbal presentations software developers results root sales staff data management sas self starter self similar field skills spss sql statistical analysis data strong attention detail problem summaries tables workloads years experience'\n",
            " ...\n",
            " 'ability able work member research team big data chemical engineering clearly succinctly publication close attention detail closely riftmap team cmac world leading medicines co wp complementary collaborative team experts computer science critical quality attributes content uniformity dissolution performance drug product daniel development digital pharmaceutical technology providers dr daniel markl excellent verbal written communications skills ability focus role development integration data four universities framework computational tools optimal design pharmaceutical processes real time process management system flexible real time release testing framework global pharmaceutical companies important data streams industry initiative key benefits industry long standing partnerships maintenance efforts rtrt environment utilisation smart assembly soft hard sensors manufacture pharmaceuticals riftmap manufacturing research centre hosts portfolio collaborative research programmes months closing date new concepts research  excellent organisational skills new data driven models new epsrc nsf project next generation novel data driven methods quality control applications operating conditions formulation pharmaceutical science  chemistry related discipline appropriate experience process data analytics phd relevant subject electrical engineering potential transform programme project reduced cost manufacture reduced time market new products reduced waste increased resilience robust transferable flexible rtrt framework responsive changes raw materials salary range       fte  term successful track record research achievement technology providers testing framework development transform development manufacture medicines uk universities university usa verified state art continuous manufacturing lines wide range pharmaceutical manufacturers world leading team process systems pharmaceutical engineers www cmac'\n",
            " \"acrosson united tech vision age ai ai consumption ai engines  services products ai engines services ai platform teams approaches associated group's work  plan assign financial material resources available software development tools best practices best practises brand expedia broader organizational efforts build network technology organizations business need business outcomes bottom line business unit function business unit function line organizational resources goals business units candid conversations critiques carrentals cheaptickets color company  role consideration employment context platform strategy core data core role capabilities influence cross division talent development cst culture cutting edge solutions daps data science machine learning engineering deep knowledge industry organisation's needs defines defines goals solutions delivers delivery demonstrate risks benefits depth development development technology implementation solutions disability diverse high quality talent pipeline diverse workforce drive talent strategy ebookers egencia embed ml engineers employer engineering envision everyone exciting new role executive exhibit expedia expedia  inc  rights expedia group expedia group expedia group expedia group travel platform   role crucial drive expedia group's family brands expedia local expert experience people management expert multiple domains familiar domains functional areas functional leadership functional programs gender  gender identity expression genetics highly skilled ml engineers hotels hotwire improved engagement sustainable economic successes improving team inclusive work environment industry leading technology solutions fuel partner growth success inform future product roadmap drive customer product education informed task insights back organization irrespective organizational boundaries key process improvement opportunities knowledge large number expedia group domains large number ml engineers expedia group lasting connections lead directors leader ml engineering leading creation leading machine machine machine learning scientists master's equivalent experience memorable experiences mentorship programs methods techniques ml capability ml engineering mentor key engineering talent ml platform capabilities end end multiple  multi year machine learning project roadmap program multiple levels people managers nasdaq expe powers national origin necessary  department homeland security dhs information network internal contacts new best practices uniquely fit organisation new employee's  confirm work authorization new software applications next wave growth ofto growtech brand open trusting environments diverse viewpoints opinions optimal location strategy orbitz organization  multi dependency outstanding judgment flexibility tailoring process team's work oversee development ownership collaboration partner solutions people pipelines talent future internal external talent pools platform design requirements product managers engineers production property respective owners proposed improvements qualified applicants rapid resolution technical issues regard race relevant parties review operating technology strategy context business goals market dynamics role key leader role report science engineering senior director set strategic direction set vision strategy sexual orientation share industry trends shared goal show specialist advisor staffing team strategic planning  execution process evolution strategies stronger links team technical customer problems top eg's data crucial success trademarks travelers travelocity trivago value millions travellers partners values veteran status vision vp vrbo wider ai & ml leadership team working collaboration product team world new ways wotif years experience bachelor's + years ® “one team” mentality ™ media solutions\"\n",
            " 'automotive companies automotive industry production bayesian gaussian good development skills benefits better informed division competitive salary confidential discussion machine learning engineer python role excellent communication collaboration skills machine learning engineer fully remote cambridge based office huge financial backing continually growing  company ideally c++ ideas research k leadership junior engineers machine learning algorithms   machine learning engineer working researchers platform engineers machine learning engineer opportunity platform python real world customer problems requirements role september point solid machine learning skills state art machine learning techniques robust scalable way successful tech company week']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-XSIwTpfCK6r",
        "outputId": "213eaccb-293a-4381-da90-203381ec78e5"
      },
      "source": [
        "kaggle_JDs.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5220,)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-hhkfNqSCCii",
        "outputId": "9e2319f0-2a20-482a-a585-ef71a411f80b"
      },
      "source": [
        "def make_dummy_var(y):\n",
        "  temp = np.zeros([len(y), 3])\n",
        "  for i in range(0,len(y)):\n",
        "    if y[i] == 'data_scientist':\n",
        "      temp[i,0] = 1\n",
        "      temp[i,1] = 0\n",
        "      temp[i,2] = 0\n",
        "    elif y[i] == 'data_analyst':\n",
        "      temp[i,0] = 0\n",
        "      temp[i,1] = 1\n",
        "      temp[i,2] = 0\n",
        "    elif y[i] == 'data_engineer':\n",
        "      temp[i,0] = 0\n",
        "      temp[i,1] = 0\n",
        "      temp[i,2] = 1\n",
        "  return temp\n",
        "\n",
        "y_onehot = make_dummy_var(y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(padded_JDs[0:5220], y_onehot, test_size=0.33)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)\n",
        "\n",
        "print(len(y_train[y_train[:,0] == 1])/(len(y_train[y_train[:,0] == 0])+len(y_train[y_train[:,0] == 1])))\n",
        "print(len(y_test[y_test[:,0] == 1])/(len(y_test[y_test[:,0] == 0])+len(y_test[y_test[:,0] == 1])))\n",
        "\n",
        "print(len(y_train[y_train[:,1] == 1])/(len(y_train[y_train[:,1] == 0])+len(y_train[y_train[:,1] == 1])))\n",
        "print(len(y_test[y_test[:,1] == 1])/(len(y_test[y_test[:,1] == 0])+len(y_test[y_test[:,1] == 1])))\n",
        "\n",
        "print(len(y_train[y_train[:,2] == 1])/(len(y_train[y_train[:,2] == 0])+len(y_train[y_train[:,2] == 1])))\n",
        "print(len(y_test[y_test[:,2] == 1])/(len(y_test[y_test[:,2] == 0])+len(y_test[y_test[:,2] == 1])))\n",
        "\n",
        "print(y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3497, 926)\n",
            "(1723, 926)\n",
            "(3497, 3)\n",
            "(1723, 3)\n",
            "0.45925078638833283\n",
            "0.4468949506674405\n",
            "0.28738919073491564\n",
            "0.3076030179918746\n",
            "0.2533600228767515\n",
            "0.24550203134068485\n",
            "[[0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " ...\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "ACHjvADMBnr0",
        "outputId": "504bddeb-eb9f-439e-a882-9201d9116de1"
      },
      "source": [
        "model = Sequential()\n",
        "# model.add(glove_layer) # uncomment this only if using pretrained embedding matrix\n",
        "model.add(Embedding(vocab_size, 100, input_length=max_length))\n",
        "model.add(SpatialDropout1D(0.2))\n",
        "model.add(Conv1D(filters=144, kernel_size=8, activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(72, activation='relu'))\n",
        "model.add(Dense(24, activation='relu'))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "\n",
        "Adam = keras.optimizers.Adam(learning_rate=0.001)\n",
        "\n",
        "model.compile(optimizer=Adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "print(model.summary())\n",
        "\n",
        "# add learning rate parameter\n",
        "\n",
        "# fit the model\n",
        "model.fit(X_train, y_train, epochs=20, verbose=1, batch_size=32)\n",
        "\n",
        "# evaluate the model\n",
        "loss, accuracy = model.evaluate(X_train, y_train, verbose=0)\n",
        "print('Accuracy: %f' % (accuracy*100))\n",
        "\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "print('Test accuracy: %f' % (test_accuracy*100))\n",
        "\n",
        "#Accuracy: 99.714041\n",
        "#54/54 [==============================] - 7s 131ms/step - loss: 0.9482 - accuracy: 0.8741\n",
        "#Test accuracy: 87.405688"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-2e56701e7c64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# model.add(glove_layer) # uncomment this only if using pretrained embedding matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSpatialDropout1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConv1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m144\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Sequential' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pC_OKMbNAR2v"
      },
      "source": [
        "indeed_job_types = model.predict(padded_JDs[5220:len(padded_JDs)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lqQ-mIS8H22C",
        "outputId": "7149c09c-3823-4cca-8091-41732720803c"
      },
      "source": [
        "print(indeed_job_types.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1143, 3)\n",
            "(1143,)\n"
          ]
        }
      ]
    }
  ]
}